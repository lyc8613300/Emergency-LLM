"""
Emergency-LLM å¾®è°ƒAPI
åŸºäº LLaMA-Factory åç«¯çš„å¾®è°ƒæ¥å£
"""

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import subprocess
import json
import os
import time
import threading
from typing import Dict, Any, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__, static_folder='static')
CORS(app)

# å…¨å±€å˜é‡å­˜å‚¨è®­ç»ƒçŠ¶æ€
training_status = {
    'status': 'idle',  # idle, training, completed, error
    'task_id': None,
    'epoch': 0,
    'step': 0,
    'total_steps': 0,
    'loss': 0.0,
    'learning_rate': 0.0,
    'progress': 0.0,
    'logs': [],
    'error': None,
    'process': None
}

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_DIR = 'configs'
OUTPUT_DIR = 'saves'
os.makedirs(CONFIG_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)


def clean_path(path: str) -> str:
    """
    æ¸…ç†è·¯å¾„å­—ç¬¦ä¸²ï¼šå»é™¤å¼•å·ã€ç©ºæ ¼å’Œæœ«å°¾æ–œæ 
    """
    if not path:
        return path
    # å»é™¤é¦–å°¾ç©ºæ ¼
    path = path.strip()
    # å»é™¤å¼•å·ï¼ˆå•å¼•å·å’ŒåŒå¼•å·ï¼‰
    path = path.strip('"').strip("'")
    # å»é™¤æœ«å°¾çš„æ–œæ 
    path = path.rstrip('/')
    return path


def convert_config_to_cli_args(config: Dict[str, Any]) -> list:
    """
    å°†å‰ç«¯é…ç½®è½¬æ¢ä¸ºLLaMA-Factoryå‘½ä»¤è¡Œå‚æ•°
    """
    args = ['llamafactory-cli', 'train']
    
    # æ¨¡å‹é…ç½® - ä¼˜å…ˆä½¿ç”¨ model_pathï¼ˆæœ¬åœ°è·¯å¾„ï¼‰ï¼Œå…¶æ¬¡æ‰ä½¿ç”¨ model_name
    if config.get('model_path') and config['model_path'].strip():
        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„
        model_path = clean_path(config['model_path'])
        args.extend(['--model_name_or_path', model_path])
    elif config.get('model_name') and config['model_name'] != 'custom':
        # å¦‚æœåªæä¾›äº†æ¨¡å‹åç§°ï¼Œä½¿ç”¨æ¨¡å‹åç§°
        model_name = clean_path(config['model_name'])
        args.extend(['--model_name_or_path', model_name])
    
    # å¾®è°ƒç±»å‹
    if config.get('finetuning_type'):
        args.extend(['--finetuning_type', config['finetuning_type']])
    
    # æ•°æ®é›†é…ç½®
    if config.get('dataset'):
        if isinstance(config['dataset'], list):
            # æ¸…ç†æ•°æ®é›†åç§°ä¸­çš„ç©ºæ ¼
            datasets = [d.strip() for d in config['dataset'] if d.strip()]
            args.extend(['--dataset', ','.join(datasets)])
        else:
            args.extend(['--dataset', config['dataset'].strip()])
    
    if config.get('dataset_dir'):
        dataset_dir = clean_path(config['dataset_dir'])
        args.extend(['--dataset_dir', dataset_dir])
    
    # è®­ç»ƒé˜¶æ®µ
    if config.get('training_stage'):
        args.extend(['--stage', config['training_stage']])
    
    # åŸºç¡€è®­ç»ƒå‚æ•°
    if config.get('learning_rate'):
        args.extend(['--learning_rate', str(config['learning_rate'])])
    
    if config.get('num_train_epochs'):
        args.extend(['--num_train_epochs', str(config['num_train_epochs'])])
    
    if config.get('max_grad_norm'):
        args.extend(['--max_grad_norm', str(config['max_grad_norm'])])
    
    if config.get('cutoff_len'):
        args.extend(['--cutoff_len', str(config['cutoff_len'])])
    
    if config.get('batch_size'):
        args.extend(['--per_device_train_batch_size', str(config['batch_size'])])
    
    if config.get('gradient_accumulation_steps'):
        args.extend(['--gradient_accumulation_steps', str(config['gradient_accumulation_steps'])])
    
    if config.get('val_size') and config['val_size'] > 0:
        args.extend(['--val_size', str(config['val_size'])])
    
    if config.get('lr_scheduler_type'):
        args.extend(['--lr_scheduler_type', config['lr_scheduler_type']])
    
    # è®¡ç®—ç²¾åº¦
    if config.get('compute_type'):
        if config['compute_type'] == 'bf16':
            args.append('--bf16')
        elif config['compute_type'] == 'fp16':
            args.append('--fp16')
    
    # é‡åŒ–é…ç½®
    if config.get('quantization_bit') and config['quantization_bit'] != 'none':
        args.extend(['--quantization_bit', config['quantization_bit']])
    
    # Template
    if config.get('template'):
        args.extend(['--template', config['template']])
    
    # LoRAé…ç½®
    if config.get('finetuning_type') == 'lora':
        if config.get('lora_rank'):
            args.extend(['--lora_rank', str(config['lora_rank'])])
        
        if config.get('lora_alpha'):
            args.extend(['--lora_alpha', str(config['lora_alpha'])])
        
        if config.get('lora_dropout'):
            args.extend(['--lora_dropout', str(config['lora_dropout'])])
        
        if config.get('lora_target'):
            args.extend(['--lora_target', config['lora_target']])
        
        if config.get('use_rslora'):
            args.append('--use_rslora')
        
        if config.get('use_dora'):
            args.append('--use_dora')
    
    # é«˜çº§é€‰é¡¹
    if config.get('logging_steps'):
        args.extend(['--logging_steps', str(config['logging_steps'])])
    
    if config.get('save_steps'):
        args.extend(['--save_steps', str(config['save_steps'])])
    
    if config.get('warmup_steps'):
        args.extend(['--warmup_steps', str(config['warmup_steps'])])
    
    if config.get('output_dir'):
        output_dir = clean_path(config['output_dir'])
        args.extend(['--output_dir', output_dir])
    else:
        args.extend(['--output_dir', os.path.join(OUTPUT_DIR, f'train_{int(time.time())}')])
    
    # DeepSpeed
    if config.get('ds_stage') and config['ds_stage'] != 'none':
        args.extend(['--deepspeed', f'ds_z{config["ds_stage"]}_config.json'])
        
        if config.get('ds_offload'):
            args.append('--deepspeed_offload')
    
    # æŠ¥å‘Šå·¥å…·
    if config.get('report_to') and config['report_to'] != 'none':
        args.extend(['--report_to', config['report_to']])
    
    # å¸ƒå°”é€‰é¡¹
    if config.get('packing'):
        args.append('--packing')
    
    if config.get('train_on_prompt'):
        args.append('--train_on_prompt')
    
    if config.get('resize_vocab'):
        args.append('--resize_vocab')
    
    # æ·»åŠ å…¶ä»–å¿…è¦å‚æ•°
    args.append('--do_train')
    args.extend(['--overwrite_output_dir', 'True'])
    
    return args


def parse_training_log(line: str) -> Optional[Dict[str, Any]]:
    """
    è§£æè®­ç»ƒæ—¥å¿—ï¼Œæå–å…³é”®ä¿¡æ¯
    æ”¯æŒçš„æ ¼å¼:
    - {'loss': 2.5, 'learning_rate': 5e-05, 'epoch': 1.0}
    - Step 100/1000: loss=2.5
    """
    try:
        result = {}
        
        # æ–¹æ³•1: è§£æåŒ…å« 'loss' çš„ JSON æ ¼å¼æ—¥å¿—ï¼ˆæ”¯æŒå•å¼•å·å’ŒåŒå¼•å·ï¼‰
        if 'loss' in line.lower() and '{' in line and '}' in line:
            # æå– JSON éƒ¨åˆ†
            start_idx = line.find('{')
            end_idx = line.rfind('}') + 1
            if start_idx != -1 and end_idx > start_idx:
                json_str = line[start_idx:end_idx]
                try:
                    # å°è¯•ç›´æ¥è§£æ
                    data = json.loads(json_str)
                except json.JSONDecodeError:
                    try:
                        # å¦‚æœå¤±è´¥ï¼Œå°è¯•å°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·
                        json_str = json_str.replace("'", '"')
                        data = json.loads(json_str)
                    except:
                        data = None
                
                if data:
                    # æå– loss
                    if 'loss' in data:
                        result['loss'] = float(data['loss'])
                    
                    # æå– epoch
                    if 'epoch' in data:
                        result['epoch'] = float(data['epoch'])
                    
                    # æå– step
                    if 'step' in data:
                        result['step'] = int(data['step'])
                    elif 'global_step' in data:
                        result['step'] = int(data['global_step'])
                    
                    # æå–å­¦ä¹ ç‡
                    if 'learning_rate' in data:
                        result['learning_rate'] = float(data['learning_rate'])
        
        # æ–¹æ³•2: è§£æç™¾åˆ†æ¯”è¿›åº¦ (ä¾‹å¦‚: "10%|â–ˆâ–ˆâ–ˆâ–ˆ      | 100/1000")
        if '%|' in line:
            import re
            match = re.search(r'(\d+)%', line)
            if match:
                progress = int(match.group(1))
                result['progress'] = progress / 100.0
            
            # æå–æ­¥æ•° (ä¾‹å¦‚: 100/1000)
            match = re.search(r'(\d+)/(\d+)', line)
            if match:
                current_step = int(match.group(1))
                total_steps = int(match.group(2))
                result['step'] = current_step
                result['total_steps'] = total_steps
                result['progress'] = current_step / total_steps if total_steps > 0 else 0
        
        # æ–¹æ³•3: è§£æå…³é”®è¯æ ¼å¼ (ä¾‹å¦‚: "Step 100: loss=2.5")
        if 'step' in line.lower() and 'loss' in line.lower():
            import re
            
            # æå– step æ•°å­—
            step_match = re.search(r'[Ss]tep\s+(\d+)', line)
            if step_match:
                result['step'] = int(step_match.group(1))
            
            # æå– loss æ•°å€¼
            loss_match = re.search(r'loss[:\s=]+(\d+\.?\d*)', line, re.IGNORECASE)
            if loss_match:
                result['loss'] = float(loss_match.group(1))
        
        # æ–¹æ³•4: è§£æ epoch ä¿¡æ¯
        if 'epoch' in line.lower():
            import re
            epoch_match = re.search(r'[Ee]poch[:\s]+(\d+\.?\d*)', line)
            if epoch_match:
                result['epoch'] = float(epoch_match.group(1))
        
        return result if result else None
        
    except Exception as e:
        logger.error(f"è§£ææ—¥å¿—å¤±è´¥: {e}")
        return None


def monitor_training_process(process: subprocess.Popen, task_id: str):
    """
    ç›‘æ§è®­ç»ƒè¿›ç¨‹ï¼Œæ›´æ–°çŠ¶æ€
    """
    global training_status
    
    try:
        # è¯»å–è¿›ç¨‹è¾“å‡º
        for line in iter(process.stdout.readline, b''):
            if line:
                decoded_line = line.decode('utf-8').strip()
                
                # è®°å½•åŸå§‹æ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                logger.info(decoded_line)
                
                # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨
                training_status['logs'].append(decoded_line)
                
                # åªä¿ç•™æœ€è¿‘50æ¡æ—¥å¿—
                if len(training_status['logs']) > 50:
                    training_status['logs'].pop(0)
                
                # è§£æè®­ç»ƒæŒ‡æ ‡
                parsed = parse_training_log(decoded_line)
                if parsed:
                    # æ›´æ–°è®­ç»ƒçŠ¶æ€ï¼Œä½†ä¸è¦†ç›–æœªæä¾›çš„å­—æ®µ
                    if 'loss' in parsed:
                        training_status['loss'] = parsed['loss']
                        logger.info(f"æ›´æ–° Loss: {parsed['loss']}")
                    
                    if 'epoch' in parsed:
                        training_status['epoch'] = parsed['epoch']
                        logger.info(f"æ›´æ–° Epoch: {parsed['epoch']}")
                    
                    if 'step' in parsed:
                        training_status['step'] = parsed['step']
                        logger.info(f"æ›´æ–° Step: {parsed['step']}")
                    
                    if 'progress' in parsed:
                        training_status['progress'] = parsed['progress']
                        logger.info(f"æ›´æ–°è¿›åº¦: {parsed['progress']:.2%}")
                    
                    if 'learning_rate' in parsed:
                        training_status['learning_rate'] = parsed['learning_rate']
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        return_code = process.wait()
        
        if return_code == 0:
            training_status['status'] = 'completed'
            training_status['progress'] = 1.0
            training_status['logs'].append("âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼")
            logger.info("è®­ç»ƒå®Œæˆ")
        else:
            training_status['status'] = 'error'
            training_status['error'] = f"è®­ç»ƒè¿›ç¨‹å¼‚å¸¸é€€å‡ºï¼Œè¿”å›ç : {return_code}"
            training_status['logs'].append(f"âŒ è®­ç»ƒå¤±è´¥ï¼š{training_status['error']}")
            logger.error(training_status['error'])
            
    except Exception as e:
        training_status['status'] = 'error'
        training_status['error'] = str(e)
        training_status['logs'].append(f"âŒ ç›‘æ§å¼‚å¸¸ï¼š{str(e)}")
        logger.error(f"ç›‘æ§è®­ç»ƒè¿›ç¨‹å¤±è´¥: {e}")
    
    finally:
        training_status['process'] = None


@app.route('/')
def index():
    """ä¸»é¡µ - è¿”å›å¾®è°ƒç•Œé¢"""
    return send_from_directory('static', 'finetune.html')


@app.route('/api/train/start', methods=['POST'])
def start_training():
    """
    å¼€å§‹è®­ç»ƒ
    """
    global training_status
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒåœ¨è¿›è¡Œ
    if training_status['status'] == 'training':
        return jsonify({
            'error': 'å·²æœ‰è®­ç»ƒä»»åŠ¡åœ¨è¿›è¡Œä¸­'
        }), 400
    
    try:
        config = request.json
        logger.info(f"æ”¶åˆ°è®­ç»ƒè¯·æ±‚: {json.dumps(config, indent=2, ensure_ascii=False)}")
        
        # éªŒè¯é…ç½®
        if not config.get('model_name') and not config.get('model_path'):
            return jsonify({'error': 'å¿…é¡»æŒ‡å®šæ¨¡å‹åç§°æˆ–è·¯å¾„'}), 400
        
        if not config.get('dataset'):
            return jsonify({'error': 'å¿…é¡»æŒ‡å®šæ•°æ®é›†'}), 400
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"train_{int(time.time())}"
        
        # ä¿å­˜é…ç½®
        config_path = os.path.join(CONFIG_DIR, f'{task_id}.json')
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        # è½¬æ¢ä¸ºå‘½ä»¤è¡Œå‚æ•°
        cli_args = convert_config_to_cli_args(config)
        
        # ç¡®å®šå®é™…ä½¿ç”¨çš„æ¨¡å‹è·¯å¾„
        actual_model = None
        if config.get('model_path') and config['model_path'].strip():
            actual_model = config['model_path']
            logger.info(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„: {actual_model}")
        elif config.get('model_name') and config['model_name'] != 'custom':
            actual_model = config['model_name']
            logger.info(f"ä½¿ç”¨æ¨¡å‹åç§°: {actual_model}")
        
        logger.info(f"è®­ç»ƒå‘½ä»¤: {' '.join(cli_args)}")
        
        # é‡ç½®è®­ç»ƒçŠ¶æ€
        training_status = {
            'status': 'training',
            'task_id': task_id,
            'epoch': 0,
            'step': 0,
            'total_steps': 0,
            'loss': 0.0,
            'learning_rate': 0.0,
            'progress': 0.0,
            'logs': [
                f"ğŸš€ ä»»åŠ¡ID: {task_id}",
                f"ğŸ“ æ¨¡å‹: {actual_model or 'N/A'}",
                f"ğŸ“Š æ•°æ®é›†: {', '.join(config.get('dataset', []))}",
                f"âš™ï¸  è®­ç»ƒå‘½ä»¤: {' '.join(cli_args)}"
            ],
            'error': None,
            'process': None
        }
        
        # è®¾ç½® GPU è®¾å¤‡
        env = os.environ.copy()
        if config.get('cuda_device') is not None:
            # å¦‚æœæŒ‡å®šäº† GPU è®¾å¤‡ï¼Œä½¿ç”¨æŒ‡å®šçš„å€¼
            cuda_device = str(config['cuda_device'])
            env['CUDA_VISIBLE_DEVICES'] = cuda_device
            logger.info(f"ä½¿ç”¨æŒ‡å®šçš„ GPU è®¾å¤‡: CUDA_VISIBLE_DEVICES={cuda_device}")
        else:
            # æœªæŒ‡å®šæ—¶ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ï¼ˆæ‰€æœ‰å¯ç”¨GPUï¼‰
            logger.info(f"æœªæŒ‡å®šGPUè®¾å¤‡ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤é…ç½®")
        
        # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
        process = subprocess.Popen(
            cli_args,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            bufsize=1,
            env=env
        )
        
        training_status['process'] = process
        
        # åœ¨åå°çº¿ç¨‹ä¸­ç›‘æ§è®­ç»ƒè¿›ç¨‹
        monitor_thread = threading.Thread(
            target=monitor_training_process,
            args=(process, task_id)
        )
        monitor_thread.daemon = True
        monitor_thread.start()
        
        return jsonify({
            'success': True,
            'task_id': task_id,
            'message': 'è®­ç»ƒå·²å¯åŠ¨'
        })
        
    except Exception as e:
        logger.error(f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {e}")
        return jsonify({
            'error': str(e)
        }), 500


@app.route('/api/train/stop', methods=['POST'])
def stop_training():
    """
    åœæ­¢è®­ç»ƒ
    """
    global training_status
    
    try:
        if training_status['status'] != 'training':
            return jsonify({'error': 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„è®­ç»ƒ'}), 400
        
        process = training_status.get('process')
        if process:
            process.terminate()
            process.wait(timeout=10)
        
        training_status['status'] = 'idle'
        training_status['logs'].append("è®­ç»ƒå·²è¢«ç”¨æˆ·åœæ­¢")
        
        return jsonify({
            'success': True,
            'message': 'è®­ç»ƒå·²åœæ­¢'
        })
        
    except Exception as e:
        logger.error(f"åœæ­¢è®­ç»ƒå¤±è´¥: {e}")
        return jsonify({
            'error': str(e)
        }), 500


@app.route('/api/train/status', methods=['GET'])
def get_training_status():
    """
    è·å–è®­ç»ƒçŠ¶æ€
    """
    task_id = request.args.get('task_id')
    
    # è¿”å›å½“å‰è®­ç»ƒçŠ¶æ€
    status_copy = training_status.copy()
    
    # ç§»é™¤processå¯¹è±¡ï¼ˆä¸å¯åºåˆ—åŒ–ï¼‰
    status_copy.pop('process', None)
    
    # åªè¿”å›æœ€æ–°çš„10æ¡æ—¥å¿—
    if len(status_copy['logs']) > 10:
        status_copy['logs'] = status_copy['logs'][-10:]
    
    return jsonify(status_copy)


@app.route('/api/export', methods=['POST'])
def export_model():
    """
    å¯¼å‡ºæ¨¡å‹ï¼ˆåˆå¹¶ LoRA é€‚é…å™¨ä¸åŸºç¡€æ¨¡å‹ï¼‰
    """
    try:
        config = request.json
        logger.info(f"æ”¶åˆ°å¯¼å‡ºè¯·æ±‚: {json.dumps(config, indent=2, ensure_ascii=False)}")
        
        # éªŒè¯å¿…å¡«å‚æ•°
        if not config.get('checkpoint_path'):
            return jsonify({
                'error': 'è¯·æŒ‡å®šæ£€æŸ¥ç‚¹è·¯å¾„ (checkpoint_path)'
            }), 400
        
        if not config.get('export_path'):
            return jsonify({
                'error': 'è¯·æŒ‡å®šå¯¼å‡ºè·¯å¾„ (export_path)'
            }), 400
        
        checkpoint_path = clean_path(config['checkpoint_path'])
        
        # æ£€æŸ¥æ˜¯å¦ä¸º LoRA é€‚é…å™¨ï¼ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨ adapter_config.jsonï¼‰
        adapter_config_path = os.path.join(checkpoint_path, 'adapter_config.json')
        is_adapter = os.path.exists(adapter_config_path)
        
        # æ„å»ºå¯¼å‡ºå‘½ä»¤
        args = ['llamafactory-cli', 'export']
        
        if is_adapter:
            # å¦‚æœæ˜¯ LoRA é€‚é…å™¨ï¼Œéœ€è¦è¯»å–åŸºç¡€æ¨¡å‹è·¯å¾„
            try:
                with open(adapter_config_path, 'r', encoding='utf-8') as f:
                    adapter_config = json.load(f)
                    base_model_path = adapter_config.get('base_model_name_or_path')
                    
                    if not base_model_path:
                        return jsonify({
                            'error': 'æ— æ³•ä» adapter_config.json ä¸­è·å–åŸºç¡€æ¨¡å‹è·¯å¾„'
                        }), 400
                    
                    # å¦‚æœå‰ç«¯æä¾›äº†åŸºç¡€æ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨å‰ç«¯çš„ï¼›å¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„
                    if config.get('base_model_path'):
                        base_model_path = clean_path(config['base_model_path'])
                    
                    logger.info(f"æ£€æµ‹åˆ° LoRA é€‚é…å™¨ï¼ŒåŸºç¡€æ¨¡å‹: {base_model_path}")
                    args.extend(['--model_name_or_path', base_model_path])
                    args.extend(['--adapter_name_or_path', checkpoint_path])
                    
            except Exception as e:
                return jsonify({
                    'error': f'è¯»å– adapter_config.json å¤±è´¥: {str(e)}'
                }), 400
        else:
            # å¦‚æœæ˜¯å®Œæ•´æ¨¡å‹ï¼Œç›´æ¥å¯¼å‡º
            logger.info(f"æ£€æµ‹åˆ°å®Œæ•´æ¨¡å‹ï¼Œç›´æ¥å¯¼å‡º")
            args.extend(['--model_name_or_path', checkpoint_path])
        
        export_path = clean_path(config['export_path'])
        args.extend(['--export_dir', export_path])
        
        # å¯¼å‡ºè®¾å¤‡ï¼ˆauto å¯ä»¥åˆ©ç”¨ GPU åŠ é€Ÿï¼‰
        export_device = config.get('export_device', 'auto')
        args.extend(['--export_device', export_device])
        
        # å…¶ä»–å¯é€‰å‚æ•°
        if config.get('export_size'):
            args.extend(['--export_size', str(config['export_size'])])
        
        if config.get('export_quantization_bit'):
            args.extend(['--export_quantization_bit', str(config['export_quantization_bit'])])
        
        logger.info(f"å¯¼å‡ºå‘½ä»¤: {' '.join(args)}")
        
        # æ‰§è¡Œå¯¼å‡º
        result = subprocess.run(
            args,
            capture_output=True,
            text=True,
            timeout=3600  # 1å°æ—¶è¶…æ—¶
        )
        
        if result.returncode == 0:
            return jsonify({
                'success': True,
                'message': 'æ¨¡å‹å¯¼å‡ºæˆåŠŸ',
                'output': result.stdout,
                'export_path': export_path
            })
        else:
            return jsonify({
                'error': 'å¯¼å‡ºå¤±è´¥',
                'details': result.stderr
            }), 500
            
    except Exception as e:
        logger.error(f"å¯¼å‡ºæ¨¡å‹å¤±è´¥: {e}")
        return jsonify({
            'error': str(e)
        }), 500


@app.route('/api/datasets', methods=['GET'])
def list_datasets():
    """
    åˆ—å‡ºå¯ç”¨çš„æ•°æ®é›†
    æ ¹æ®æŒ‡å®šçš„ dataset_dir è¯»å– dataset_info.json æ–‡ä»¶ï¼Œè¿”å›æ•°æ®é›†åˆ—è¡¨åŠå…¶è¯¦ç»†ä¿¡æ¯
    """
    try:
        dataset_dir = request.args.get('dataset_dir', 'data')
        dataset_dir = clean_path(dataset_dir)
        
        # è¯»å–dataset_info.json
        dataset_info_path = os.path.join(dataset_dir, 'dataset_info.json')
        
        if os.path.exists(dataset_info_path):
            with open(dataset_info_path, 'r', encoding='utf-8') as f:
                dataset_info = json.load(f)
            
            # æ„å»ºæ•°æ®é›†åˆ—è¡¨ï¼ŒåŒ…å«æ›´å¤šä¿¡æ¯
            datasets = []
            for name, info in dataset_info.items():
                datasets.append({
                    'name': name,
                    'file_name': info.get('file_name', ''),
                    'file_sha1': info.get('file_sha1', ''),
                    'ranking': info.get('ranking', True),
                    'formatting': info.get('formatting', 'alpaca')
                })
            
            return jsonify({
                'success': True,
                'datasets': datasets,
                'dataset_dir': dataset_dir,
                'total': len(datasets)
            })
        else:
            logger.warning(f"æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {dataset_info_path}")
            return jsonify({
                'success': False,
                'datasets': [],
                'dataset_dir': dataset_dir,
                'total': 0,
                'message': f'æœªæ‰¾åˆ° dataset_info.json æ–‡ä»¶ï¼Œè¯·ç¡®è®¤ç›®å½• {dataset_dir} æ˜¯å¦æ­£ç¡®'
            })
            
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ•°æ®é›†å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'datasets': [],
            'total': 0
        }), 500


@app.route('/api/config/save', methods=['POST'])
def save_config():
    """
    ä¿å­˜è®­ç»ƒé…ç½®
    """
    try:
        config = request.json
        config_name = config.get('config_name', f'config_{int(time.time())}')
        
        config_path = os.path.join(CONFIG_DIR, f'{config_name}.json')
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': f'é…ç½®å·²ä¿å­˜åˆ° {config_path}'
        })
        
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return jsonify({
            'error': str(e)
        }), 500


@app.route('/api/config/list', methods=['GET'])
def list_configs():
    """
    åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„é…ç½®
    """
    try:
        configs = []
        
        if os.path.exists(CONFIG_DIR):
            for filename in os.listdir(CONFIG_DIR):
                if filename.endswith('.json'):
                    configs.append(filename[:-5])  # ç§»é™¤.jsonåç¼€
        
        return jsonify({
            'success': True,
            'configs': configs
        })
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºé…ç½®å¤±è´¥: {e}")
        return jsonify({
            'error': str(e)
        }), 500


if __name__ == '__main__':
    print("="*60)
    print("Emergency-LLM å¾®è°ƒAPIæœåŠ¡å™¨")
    print("="*60)
    print(f"è®¿é—®åœ°å€: http://localhost:5000")
    print(f"é…ç½®ç›®å½•: {os.path.abspath(CONFIG_DIR)}")
    print(f"è¾“å‡ºç›®å½•: {os.path.abspath(OUTPUT_DIR)}")
    print("="*60)
    
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=True,
        threaded=True
    )

